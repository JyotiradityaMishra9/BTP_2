{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zkMyK2RGwzMT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Set seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3GHDZOKoXmV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "meta = pd.read_csv('Train_Test_Split.csv')\n",
        "meta = meta[meta['label'].isin(['AD', 'Healthy'])]\n",
        "\n",
        "train_meta = meta[meta['split'] == 'train']\n",
        "test_meta = meta[meta['split'] == 'test']\n",
        "\n",
        "def load_and_segment(subject_id, data_dir='Data_sampled_128HZ', segment_len=1024):\n",
        "    file_path = os.path.join(data_dir, f\"{subject_id}_data.npy\")\n",
        "    data = np.load(file_path)\n",
        "    _, time_steps = data.shape\n",
        "    num_segments = time_steps // segment_len\n",
        "    if num_segments == 0:\n",
        "        return np.empty((0, 19, segment_len))\n",
        "    data = data[:, :num_segments * segment_len]\n",
        "    segments = data.reshape(19, num_segments, segment_len).transpose(1, 0, 2)\n",
        "    return segments\n",
        "\n",
        "def process_data(meta_df, data_dir='Data_sampled_128HZ'):\n",
        "    X = []\n",
        "    y = []\n",
        "    label_map = {'AD': 1, 'Healthy': 0}\n",
        "    for _, row in meta_df.iterrows():\n",
        "        segments = load_and_segment(row['subject_id'], data_dir)\n",
        "        if segments.shape[0] == 0:\n",
        "            continue\n",
        "        X.append(segments)\n",
        "        label = label_map[row['label']]\n",
        "        one_hot = np.eye(2)[label]\n",
        "        y.extend([one_hot] * segments.shape[0])\n",
        "    X = np.concatenate(X, axis=0)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "X_train, y_train = process_data(train_meta)\n",
        "X_test, y_test = process_data(test_meta)\n",
        "X_train = (X_train * 1e6) - np.mean(X_train * 1e6, axis=2, keepdims=True)\n",
        "X_test = (X_test * 1e6) - np.mean(X_test * 1e6, axis=2, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2tG3wLIpR8N",
        "outputId": "6b4b2c30-e942-4236-955d-3f9528ae27f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6927 - loss: 1.3981 - val_accuracy: 0.5065 - val_loss: 0.6353 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8645 - loss: 0.3131 - val_accuracy: 0.5168 - val_loss: 0.7012 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9097 - loss: 0.2116 - val_accuracy: 0.7144 - val_loss: 0.5337 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9366 - loss: 0.1588 - val_accuracy: 0.8162 - val_loss: 0.5183 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.1144 - val_accuracy: 0.8223 - val_loss: 0.7905 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9706 - loss: 0.0828 - val_accuracy: 0.8464 - val_loss: 0.7568 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9652 - loss: 0.0872 - val_accuracy: 0.8154 - val_loss: 0.7868 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9748 - loss: 0.0716 - val_accuracy: 0.8361 - val_loss: 1.3026 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9764 - loss: 0.0583 - val_accuracy: 0.8326 - val_loss: 0.6982 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0499 - val_accuracy: 0.8223 - val_loss: 1.4869 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 0.0324 - val_accuracy: 0.8179 - val_loss: 1.2859 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9940 - loss: 0.0175 - val_accuracy: 0.8481 - val_loss: 1.4145 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9904 - loss: 0.0241 - val_accuracy: 0.8214 - val_loss: 1.2330 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9979 - loss: 0.0096 - val_accuracy: 0.8318 - val_loss: 1.5930 - learning_rate: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "from scipy.signal import welch\n",
        "\n",
        "def compute_spectral_features(X, fs=128, nperseg=256):\n",
        "    num_segments, num_channels, num_samples = X.shape\n",
        "    psd_all = []\n",
        "\n",
        "    for seg in X:\n",
        "        seg_psd = []\n",
        "        for ch in seg:\n",
        "            freqs, psd = welch(ch, fs=fs, nperseg=nperseg)\n",
        "            seg_psd.append(psd)\n",
        "        psd_all.append(seg_psd)\n",
        "\n",
        "    psd_all = np.array(psd_all)  \n",
        "    psd_all = np.log1p(psd_all)  \n",
        "    return psd_all, freqs\n",
        "\n",
        "X_train_spec, freqs = compute_spectral_features(X_train)\n",
        "X_test_spec, _ = compute_spectral_features(X_test)\n",
        "\n",
        "X_train_spec = X_train_spec[..., np.newaxis]  # shape: (N, 19, freq_bins, 1)\n",
        "X_test_spec = X_test_spec[..., np.newaxis]\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "def create_spectral_cnn(input_shape, dropout_rate=0.3, dense_dim=128):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(dense_dim, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "input_shape = X_train_spec.shape[1:] \n",
        "model = create_spectral_cnn(input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_spec, y_train,\n",
        "    validation_data=(X_test_spec, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbNpgENupz6H",
        "outputId": "14547bf0-cfda-42c2-9ae8-f12e469bd02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "ROC AUC: 0.8947969086987779\n",
            "Average Precision: 0.8570660650921323\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.83      0.81       535\n",
            "           1       0.85      0.80      0.82       624\n",
            "\n",
            "    accuracy                           0.82      1159\n",
            "   macro avg       0.82      0.82      0.82      1159\n",
            "weighted avg       0.82      0.82      0.82      1159\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
        "\n",
        "y_pred = model.predict(X_test_spec)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"ROC AUC:\", roc_auc_score(y_true, y_pred[:, 1]))\n",
        "print(\"Average Precision:\", average_precision_score(y_true, y_pred[:, 1]))\n",
        "print(classification_report(y_true, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JQixnES1iM4"
      },
      "outputs": [],
      "source": [
        "output_folder = \"Models\"\n",
        "os.makedirs(output_folder,exist_ok=True)\n",
        "model_path = os.path.join(output_folder,\"Final_CNNSpectral_model.keras\")\n",
        "model.save(model_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
